{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import csv\n",
    "import pandas as pd\n",
    "import scipy.sparse as sc\n",
    "from helpers import *\n",
    "from sgd import *\n",
    "from sklearn import decomposition\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of items: 10000, number of users: 1000\n"
     ]
    }
   ],
   "source": [
    "ratings = load_data('data_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_items_per_user = np.array((ratings != 0).sum(axis=0)).flatten()\n",
    "num_users_per_item = np.array((ratings != 0).sum(axis=1).T).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the shape of original ratings. (# of row, # of col): (10000, 1000)\n",
      "the shape of valid ratings. (# of row, # of col): (9990, 999)\n",
      "Total number of nonzero elements in origial data:1176952\n",
      "Total number of nonzero elements in train data:1065253\n",
      "Total number of nonzero elements in test data:111620\n"
     ]
    }
   ],
   "source": [
    "_,train, test = split_data(ratings, num_items_per_user, num_users_per_item, 10, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9990, 999)\n",
      "learn the matrix factorization using SGD...\n",
      "iter: 0, RMSE on training set: 0.997560255008501.\n",
      "iter: 1, RMSE on training set: 0.9842293566398914.\n",
      "iter: 2, RMSE on training set: 0.9780387061695399.\n",
      "iter: 3, RMSE on training set: 0.9723799399467854.\n",
      "iter: 4, RMSE on training set: 0.969301806280314.\n",
      "iter: 5, RMSE on training set: 0.9667096170339626.\n",
      "iter: 6, RMSE on training set: 0.964171308803295.\n",
      "iter: 7, RMSE on training set: 0.9629057008668301.\n",
      "iter: 8, RMSE on training set: 0.9620649935787686.\n",
      "iter: 9, RMSE on training set: 0.9603911798400415.\n",
      "iter: 10, RMSE on training set: 0.959463560281415.\n",
      "iter: 11, RMSE on training set: 0.9585125420480426.\n",
      "iter: 12, RMSE on training set: 0.9581533270460627.\n",
      "iter: 13, RMSE on training set: 0.957696042239014.\n",
      "iter: 14, RMSE on training set: 0.9571881375998007.\n",
      "iter: 15, RMSE on training set: 0.9567520143874916.\n",
      "iter: 16, RMSE on training set: 0.9566212727648964.\n",
      "iter: 17, RMSE on training set: 0.9561960422110439.\n",
      "iter: 18, RMSE on training set: 0.9560632533981644.\n",
      "iter: 19, RMSE on training set: 0.956011603975843.\n"
     ]
    }
   ],
   "source": [
    "print(train.shape)\n",
    "predict = matrix_factorization_SGD(ratings, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_row_and_col(line):\n",
    "    ids, rating = line.split(',')\n",
    "    user_id, movie_id = ids.split('_')\n",
    "    user_id = user_id.replace('r', '')\n",
    "    movie_id = movie_id.replace('c', '')\n",
    "    return int(user_id), int(movie_id)\n",
    "\n",
    "def create_csv_submissions(predict):\n",
    "    f = open('sample_submission.csv', 'r')\n",
    "    data = f.read().splitlines()[1:]\n",
    "    to_predict = [(get_row_and_col(line)[0], get_row_and_col(line)[1]) for line in data]\n",
    "    \n",
    "    with open(\"submission.csv\", 'w') as csvfile:\n",
    "        fieldnames = ['Id', 'Prediction']\n",
    "        writer = csv.DictWriter(csvfile, delimiter=\",\", fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "        for row, col in to_predict:\n",
    "            writer.writerow({'Id':\"r\" + str(row) + \"_c\" + str(col),'Prediction':str(predict[row-1, col-1])})\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "create_csv_submissions(predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 1000)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
