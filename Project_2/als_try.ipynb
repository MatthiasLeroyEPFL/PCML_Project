{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import csv\n",
    "import pandas as pd\n",
    "import scipy.sparse as sc\n",
    "from helpers import *\n",
    "from als import *\n",
    "from sklearn import decomposition\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of items: 10000, number of users: 1000\n"
     ]
    }
   ],
   "source": [
    "ratings = load_data('data_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_items_per_user = np.array((ratings != 0).sum(axis=0)).flatten()\n",
    "num_users_per_item = np.array((ratings != 0).sum(axis=1).T).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the shape of original ratings. (# of row, # of col): (10000, 1000)\n",
      "the shape of valid ratings. (# of row, # of col): (9990, 999)\n",
      "Total number of nonzero elements in origial data:1176952\n",
      "Total number of nonzero elements in train data:1065253\n",
      "Total number of nonzero elements in test data:111620\n"
     ]
    }
   ],
   "source": [
    "_,train, test = split_data(ratings, num_items_per_user, num_users_per_item, 10, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = decomposition.NMF(n_components=3)\n",
    "W = model.fit_transform(train)\n",
    "Z = model.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 999)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "start the ALS algorithm...\n",
      "RMSE on training set: 0.9697751806835305.\n",
      "RMSE on training set: 0.9652521967234385.\n",
      "RMSE on training set: 0.9637298175089041.\n",
      "RMSE on training set: 0.9625029911692241.\n",
      "RMSE on training set: 0.96151340878739.\n",
      "RMSE on training set: 0.9608201400665092.\n",
      "RMSE on training set: 0.9603902940452437.\n",
      "RMSE on training set: 0.9601438316572578.\n",
      "RMSE on training set: 0.9600078549084466.\n",
      "RMSE on training set: 0.9599332982742421.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#ALS(train,test,3)\n",
    "predict = ALS(ratings, None,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_row_and_col(line):\n",
    "    ids, rating = line.split(',')\n",
    "    user_id, movie_id = ids.split('_')\n",
    "    user_id = user_id.replace('r', '')\n",
    "    movie_id = movie_id.replace('c', '')\n",
    "    return int(user_id), int(movie_id)\n",
    "\n",
    "def create_csv_submissions(predict):\n",
    "    f = open('sample_submission.csv', 'r')\n",
    "    data = f.read().splitlines()[1:]\n",
    "    to_predict = [(get_row_and_col(line)[0], get_row_and_col(line)[1]) for line in data]\n",
    "    \n",
    "    with open(\"submission.csv\", 'w') as csvfile:\n",
    "        fieldnames = ['Id', 'Prediction']\n",
    "        writer = csv.DictWriter(csvfile, delimiter=\",\", fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "        for row, col in to_predict:\n",
    "            writer.writerow({'Id':\"r\" + str(row) + \"_c\" + str(col),'Prediction':str(predict[row-1, col-1])})\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "create_csv_submissions(predict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
